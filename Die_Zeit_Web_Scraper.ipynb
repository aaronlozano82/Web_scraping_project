{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Die_Zeit_Web_Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HcOlndfh9XwA"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/este7734/Web_scraping_project/blob/master/Die_Zeit_Web_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bps20joHXZod",
        "colab_type": "text"
      },
      "source": [
        "# <font color='yellow'> Die Zeit Web Scraper </font>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWXpudN7R3Qc",
        "colab_type": "text"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_F9Q7Td-sRVi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "a8d23387-5af1-4449-e7d2-fc9a38d77ef8"
      },
      "source": [
        "# Import libraries for processing web text\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "from textblob import TextBlob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from lxml import html\n",
        "\n",
        "# Import these dependencies if using Google Colab \n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLQoyopg1oiY",
        "colab_type": "text"
      },
      "source": [
        "## Define All Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "form",
        "id": "mh-Z_yZsENF2",
        "colab": {}
      },
      "source": [
        "#@title Functions Hidden\n",
        "# Get content of the webpage in an html string format by passing a url \n",
        "def get_html(url):\n",
        "    page = requests.get(url)\n",
        "    html_out = html.fromstring(page.content)\n",
        "    text = page.text\n",
        "    return html_out, text\n",
        "\n",
        "# Convert html into soup to enable soup menthods\n",
        "def get_soup(html_string):\n",
        "    soup = BeautifulSoup(html_string, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "# Extract hyperlinks from soup\n",
        "def get_soup_links(soup):\n",
        "    links = []\n",
        "    for link in soup.find_all('a'):\n",
        "        out_link = link.get('href')\n",
        "        links.append(out_link)\n",
        "    return links\n",
        "\n",
        "# This function is for use with only the Topic pages on reuters.com\n",
        "# Search through ALL links and filter for only those that are for actual articles\n",
        "# links are formatted differently \n",
        "def get_articles_reuters_topics(links, old_url_set):\n",
        "    articles = []\n",
        "    for link in links:\n",
        "        try:\n",
        "            if 'https://www.zeit.de'in link:\n",
        "              for topic in die_zeit_topics:\n",
        "                if topic in link:\n",
        "                  link = link\n",
        "                  if url_check(old_url_set, link) == False:\n",
        "                    articles.append(link)\n",
        "        except:\n",
        "            continue\n",
        "    articles = list(set(articles))\n",
        "    old_url_set = set(articles + list(old_url_set))       \n",
        "    return articles, old_url_set\n",
        "\n",
        "# Check if new urls exists in the old_url_set. if yes, return True; if no, return False\n",
        "# This function is used in the get_articles_reuters_topics function\n",
        "def url_check(old_url_set, url):\n",
        "    url_set = set([url])\n",
        "    test_set = old_url_set & url_set\n",
        "    if len(test_set) == 0:\n",
        "        check = False\n",
        "    else:\n",
        "        check = True\n",
        "    return check\n",
        "\n",
        "# Get html strings from list of article weblinks\n",
        "def get_html_reuters(articles):\n",
        "    soup_list = []\n",
        "    for article in articles:\n",
        "        _, text = get_html(article)\n",
        "        soup = get_soup(text)\n",
        "        soup_list.append(soup)\n",
        "    return soup_list\n",
        "\n",
        "  # Break out article_body, article_headline, and article_date from each article in provided hyperlinks and put into a dictionary called: out_list\n",
        "def get_reuters_elements(soup_list, articles):\n",
        "    out_list = []\n",
        "    i = 0\n",
        "    for article in soup_list:\n",
        "        link = articles[i] # I don't think this is used at all here, which means there is no reason to require the second argument: articles\n",
        "        i += 1\n",
        "        try:\n",
        "            article_body = article.find_all(body_class, {'class': body_tag})\n",
        "            article_p = []\n",
        "            for item in article_body:\n",
        "                p_list = item.find_all('p')\n",
        "                for p in p_list:\n",
        "                    article_p.append(p.text)\n",
        "            out_text = ' '.join(article_p)\n",
        "            if out_text == '':\n",
        "              continue\n",
        "            if out_text.startswith('Besondere Reportagen'):\n",
        "              continue\n",
        "            out_dict = dict([('Text',out_text),('url',link)])\n",
        "            out_list.append(out_dict)\n",
        "        except:\n",
        "            print('Unable to decode...skipping article...')\n",
        "            continue\n",
        "\n",
        "    return out_list  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_qCIHy31uSJ",
        "colab_type": "text"
      },
      "source": [
        "## Define URL Variables and Run Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU0yQpNqLwl4",
        "colab_type": "text"
      },
      "source": [
        "Step 1. Instantiate `tags and values`. Then instntiate `old_url_set` to be used in the `get_articles_reuters_topics` function. This is a running log of article links that will be compiled by iterating from steps 2 - 6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S4mzVpzp5g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Die Zeit classes and tags\n",
        "body_class = 'div'\n",
        "headline_class = 'h1'\n",
        "date_class = 'div'\n",
        "\n",
        "body_tag = 'article-body article-body--article'\n",
        "headline_tag = 'headline article__item'\n",
        "date_tag = 'metadata'\n",
        "\n",
        "# Instantiate empty set to use a running list of hyperlinks while \n",
        "# running the scrape iterations\n",
        "old_url_set = set([])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBkhWZ5iMWq9",
        "colab_type": "text"
      },
      "source": [
        "## Scrape Reuters Topics pages for all the most recent news articles. <font color='orange'>*Run Steps 2 - 3 for each instance of `url` variable, before moving on to the next steps*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URLqBDPwUbRZ",
        "colab_type": "text"
      },
      "source": [
        "<font color='orange'>Step 2.</font> Define variables for each of Reuters main topics pages. Run this cell for each iteration by uncommenting a different url each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8a1cAaw3PfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define url variables\n",
        "# NOTE: You must run these individually through the end of this section\n",
        "# I didn't have time to figure out how to loop through all of them properly\n",
        "# There is a section at the very bottom where you can see that I attempted but ran\n",
        "# into a problem on one of the last functions. \n",
        "\n",
        "# Die Zeit Links\n",
        "#url = r'https://www.zeit.de/index'\n",
        "#url = r'https://www.zeit.de/politik/index'\n",
        "url = r'https://www.zeit.de/gesellschaft/index'\n",
        "#url = r'https://www.zeit.de/wirtschaft/index'\n",
        "#url = r'https://www.zeit.de/wissen/index'\n",
        "#url = r'https://www.zeit.de/digital/index'\n",
        "#url = r'https://www.zeit.de/entdecken/index'\n",
        "#url = r'https://www.zeit.de/zeit-magazin/index'\n",
        "\n",
        "die_zeit_topics = ['politik/index', 'gesellschaft', 'wirtschaft', 'wissen',\n",
        "                   'digital', 'entdecken']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qGyTkHR3Tos",
        "colab_type": "text"
      },
      "source": [
        "## Scraper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctx4uUaNM-qy",
        "colab_type": "text"
      },
      "source": [
        "<font color='orange'>Step 3.</font> Get HTML srting from web `url`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJshIC2L4iPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a69e0f55-90b2-4317-c28e-31861247f4c4"
      },
      "source": [
        "# Pass the each instance of `url` variable to return the web page in HTML format and convert it to a string\n",
        "html_string = str(get_html(url))\n",
        "# Pass the HTML string (of the web page) to get its soup\n",
        "soup = get_soup(html_string)\n",
        "# Find ALL links on within the soup\n",
        "links = get_soup_links(soup)\n",
        "# Use this for Topics Pages only\n",
        "# Filter out only those links that are for actual articles. We only want the \"good\" links\n",
        "# This filters out things like links to images and advertisements or non-news worthy pages\n",
        "articles, old_url_set = get_articles_reuters_topics(links, old_url_set)\n",
        "print(len(articles))\n",
        "# Print out the running list of hyperlinks to see how many you have\n",
        "print(len(old_url_set))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44\n",
            "44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNqPBrCDCP4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linkers = list(old_url_set)\n",
        "linkers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWBBUihX8R0w",
        "colab_type": "text"
      },
      "source": [
        "## <font color='skyblue'>Parse soup from entire list of hyperlinks that you just accumulated</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5M5Po9_OWk2",
        "colab_type": "text"
      },
      "source": [
        "Step 8. Get soup for every link\n",
        "\n",
        "Step 9. Parse the soup for each link into `article_body`, `article_title`, and `article_date`. Create list of dictionaries for each web page\n",
        "\n",
        "Step 10. Run `TextBlob` on list of dictionaries to separate all sentences in a single list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZoenVkMIukU",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "60665932-334a-488d-bdee-ef30de98b721"
      },
      "source": [
        "# Get soup for each one of the \"good\" links\n",
        "url_links = list(old_url_set) # Convert the running set of links to a list for use in the following functions\n",
        "\n",
        "soup_list = get_html_reuters(url_links)\n",
        "print(f'Length of Soup List: {len(soup_list)}')\n",
        "#print(soup_list[0])\n",
        "\n",
        "# Parse the soup for each \"good\" link to get article text, title, and date\n",
        "out_list = get_reuters_elements(soup_list, url_links)\n",
        "print(f'Length of out_list: {len(out_list)}')\n",
        "#out_list[0:2]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of Soup List: 44\n",
            "Length of out_list: 34\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO7ZWsj3GFWg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "35a6bdd9-a9aa-4665-823b-932d048c61b5"
      },
      "source": [
        "blob_sentences =[]\n",
        "for i in range(len(out_list)):\n",
        "  try:\n",
        "    blob = out_list[i]['Text']\n",
        "    trans = TextBlob(blob) # Enter string object\n",
        "    trans = trans.translate(to='en')\n",
        "    trans = str(trans) # Change to = 'en' for English\n",
        "    trans = TextBlob(trans)\n",
        "    for item in trans.sentences:\n",
        "      blob_sentences.append(trans)\n",
        "    #print('\\n', i+1, '\\n',trans)\n",
        "  except:\n",
        "    print('got an error ...., skipping article....')\n",
        "print(f'\\nYou have {len(blob_sentences)} total sentences from {i+1} different articles')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "You have 858 total sentences from 34 different articles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XjoXSZDPHLr",
        "colab_type": "text"
      },
      "source": [
        "This is just a troubleshooting section to ensure you're `TextBlob` came out right. You should see a list of stentences, each starting with the word `Sentence`. Check this before moving to the next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4fJQzcl5X3h",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Hidden for Troubleshooting\n",
        "# print the first 6 sentences so you see what it looks like\n",
        "blob_sentences[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGJmYoaJYF_n",
        "colab_type": "text"
      },
      "source": [
        "## <font color='skyblue'> Keyword Search </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkcNzckEPdOf",
        "colab_type": "text"
      },
      "source": [
        "Step 11. Determine key words used to search for event of interest in all the articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xN0ZSBJ510j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9da692f4-47f9-471c-dbb2-15551e57726b"
      },
      "source": [
        "# Allow user to type in key words to search the text for\n",
        "# Note this is case sensitive... so you need to make sure you enter your search \n",
        "# Try the entering the following to see some results: corona,COVID,death\n",
        "filter_list = input(\"Enter key words to search for separated by commas. don't use spaces.\\nSearch is case sensitive.\\nExample search: coronavirus,COVID,death\\n\\n\") #.title() # This is still a string... not a list yet"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter key words to search for separated by commas. don't use spaces.\n",
            "Search is case sensitive.\n",
            "Example search: coronavirus,COVID,death\n",
            "\n",
            "America\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8asVgYSPsbu",
        "colab_type": "text"
      },
      "source": [
        "Step 12. Convert keywords into an iterable list for use in the next step\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49R1H35B7aH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e5c8d29-fcfa-4090-f039-90aff992db51"
      },
      "source": [
        "# Split filter words and convert into a list for itterating in the next step \n",
        "\n",
        "f = []\n",
        "for word in (filter_list.split(\",\")):  # Split string into separate words, separate by comma\n",
        "  f.append(word)                       # Generate new list containing each key word\n",
        "f # This is now a list of key words that the user typed in"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['America']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTNasDzQLinR",
        "colab_type": "text"
      },
      "source": [
        "Step 13. <font color='skyblue'> Search </font>  All sentences for Key Words and return only those consisting of a key word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXjYMd1-LUrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "aa46164a-ed95-42b3-b0dd-a5b34642384c"
      },
      "source": [
        "# Instantiate list for holding the sentences\n",
        "sentences = []\n",
        "\n",
        "# Generate empty list of lists to store the sentences with your key words in them\n",
        "for i in range(len(f)):\n",
        "  sentences.append([])\n",
        "#print('Here is what you just made, and empty list of lists: ', sentences, '\\n')\n",
        "\n",
        "# Generate lists of sentences for each key word and plug them into the list of lists from above            \n",
        "for i in range(len(f)):\n",
        "  for sentence in blob_sentences:\n",
        "    if f[i] in sentence:\n",
        "        sentences[i].append(sentence)\n",
        "\n",
        "file_Die_Zeit = open(\"MyFile_Die_Zeit.txt\", \"w\") \n",
        "file_Die_Zeit.write(str(sentences))\n",
        "file_Die_Zeit.close()\n",
        "        \n",
        "# Print number of sentences containing each key word\n",
        "# Print out all sentences containing each key word\n",
        "for i in range(len(f)):\n",
        "  print('='*200)   \n",
        "  print('\\nThere are {} sentences containing the word: {} '.format(len(sentences[i]), f[i])) \n",
        "  print('-'*200)   \n",
        "  #for sentence in sentences[i]:\n",
        "      #print(sentence)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========================================================================================================================================================================================================\n",
            "\n",
            "There are 13 sentences containing the word: America \n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcOlndfh9XwA",
        "colab_type": "text"
      },
      "source": [
        "## <font color='black'>Step 13. Store All article data in DataFrame </font>  \n",
        "<font color='grey'>Note: This is not just the filtered data, this contains all information from each web page. While not used in this project, it represents all of the original data used in this run. It can be used for reference.</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjj8Wi-4yOSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1005368a-898d-4d07-8a0d-494c90f542a5"
      },
      "source": [
        "# Put parsed data into Pandas DataFrame\n",
        "pd.DataFrame(out_list)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Urlaubsgäste aus den Kreisen Gütersloh und War...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/2020-06/coron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trotz Kontaktbeschränkungen sind Zehntausende ...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/2020-06/gross...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Maskenpflicht in Zügen und Flugzeugen, Einbahn...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mehr als ein Dutzend verletzte Polizisten und ...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Die Zahl der Sterbefälle in Deutschland im Mai...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/2020-06/coron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>In der Schweiz soll die Ehe für alle zugelasse...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/familie/2020-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ein Londoner Gericht hat einen Mann mit IS-Ver...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Nach den Ausschreitungen in der Stuttgarter In...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Das Ziel des gemeinsamen Lernens von Schülerin...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/schule/2020-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>In Göttingen haben Bewohner und Bewohnerinnen ...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/2020-06/goett...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Immer mehr Mädchen und Frauen in Deutschland w...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Umweltaktivisten haben die Braunkohlegelände G...</td>\n",
              "      <td>https://www.zeit.de/wirtschaft/2020-06/braunko...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Die Bundesregierung stellt den wegen der Coron...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>In der schottischen Stadt Glasgow sind mehrere...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Der tödliche Ebola-Ausbruch im Osten der Demok...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>\\nSeit gut einer Woche können Studierende Noth...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Mehr als eine halbe Million Menschen sind im v...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Eltern sollen staatliche Leistungen für ihr Ki...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/familie/2020-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Von Madame de Staël stammt der Spruch: \"Alles ...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Mütter verdienen einer Studie zufolge aufs ges...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/familie/2020-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Das deutsche Rettungsschiff Sea-Watch 3 mit 21...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Eine junge Mutter aus bürgerlichen Verhältniss...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/2020-06/mord-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>\\nDie\\ngriechische Regierung will die überfüll...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Bei Protesten gegen die Wiedereröffnung des Pa...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Rassismus ordnet unser Denken und Zusammenlebe...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Nach einem größeren Corona-Ausbruch in einem S...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Rassismus ordnet unser Denken und Zusammenleb...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Der Schwerpunkt des neuen Nationalen Bildungsb...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/schule/2020-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Viel Zeit allein zu Hause, Langeweile, finanzi...</td>\n",
              "      <td>https://www.zeit.de/wissen/gesundheit/2020-05/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Bundesbildungsministerin Anja Karliczek hält d...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/schule/2020-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Stuttgart, 36 Stunden danach. Über die Königst...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>In Göttingen ist die Quarantäne für ein komple...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Nach dem Corona-Ausbruch beim Fleischverarbeit...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Bei regionalen Corona-Ausbrüchen sollten nach ...</td>\n",
              "      <td>https://www.zeit.de/gesellschaft/zeitgeschehen...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Text                                                url\n",
              "0   Urlaubsgäste aus den Kreisen Gütersloh und War...  https://www.zeit.de/gesellschaft/2020-06/coron...\n",
              "1   Trotz Kontaktbeschränkungen sind Zehntausende ...  https://www.zeit.de/gesellschaft/2020-06/gross...\n",
              "2   Maskenpflicht in Zügen und Flugzeugen, Einbahn...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "3   Mehr als ein Dutzend verletzte Polizisten und ...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "4   Die Zahl der Sterbefälle in Deutschland im Mai...  https://www.zeit.de/gesellschaft/2020-06/coron...\n",
              "5   In der Schweiz soll die Ehe für alle zugelasse...  https://www.zeit.de/gesellschaft/familie/2020-...\n",
              "6   Ein Londoner Gericht hat einen Mann mit IS-Ver...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "7   Nach den Ausschreitungen in der Stuttgarter In...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "8   Das Ziel des gemeinsamen Lernens von Schülerin...  https://www.zeit.de/gesellschaft/schule/2020-0...\n",
              "9   In Göttingen haben Bewohner und Bewohnerinnen ...  https://www.zeit.de/gesellschaft/2020-06/goett...\n",
              "10  Immer mehr Mädchen und Frauen in Deutschland w...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "11  Umweltaktivisten haben die Braunkohlegelände G...  https://www.zeit.de/wirtschaft/2020-06/braunko...\n",
              "12  Die Bundesregierung stellt den wegen der Coron...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "13  In der schottischen Stadt Glasgow sind mehrere...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "14  Der tödliche Ebola-Ausbruch im Osten der Demok...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "15  \\nSeit gut einer Woche können Studierende Noth...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "16  Mehr als eine halbe Million Menschen sind im v...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "17  Eltern sollen staatliche Leistungen für ihr Ki...  https://www.zeit.de/gesellschaft/familie/2020-...\n",
              "18  Von Madame de Staël stammt der Spruch: \"Alles ...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "19  Mütter verdienen einer Studie zufolge aufs ges...  https://www.zeit.de/gesellschaft/familie/2020-...\n",
              "20  Das deutsche Rettungsschiff Sea-Watch 3 mit 21...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "21  Eine junge Mutter aus bürgerlichen Verhältniss...  https://www.zeit.de/gesellschaft/2020-06/mord-...\n",
              "22  \\nDie\\ngriechische Regierung will die überfüll...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "23  Bei Protesten gegen die Wiedereröffnung des Pa...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "24  Rassismus ordnet unser Denken und Zusammenlebe...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "25  Nach einem größeren Corona-Ausbruch in einem S...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "26   Rassismus ordnet unser Denken und Zusammenleb...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "27  Der Schwerpunkt des neuen Nationalen Bildungsb...  https://www.zeit.de/gesellschaft/schule/2020-0...\n",
              "28  Viel Zeit allein zu Hause, Langeweile, finanzi...  https://www.zeit.de/wissen/gesundheit/2020-05/...\n",
              "29  Bundesbildungsministerin Anja Karliczek hält d...  https://www.zeit.de/gesellschaft/schule/2020-0...\n",
              "30  Stuttgart, 36 Stunden danach. Über die Königst...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "31  In Göttingen ist die Quarantäne für ein komple...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "32  Nach dem Corona-Ausbruch beim Fleischverarbeit...  https://www.zeit.de/gesellschaft/zeitgeschehen...\n",
              "33  Bei regionalen Corona-Ausbrüchen sollten nach ...  https://www.zeit.de/gesellschaft/zeitgeschehen..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}