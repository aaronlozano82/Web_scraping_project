{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Welt_Web_Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "HcOlndfh9XwA"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/este7734/Web_scraping_project/blob/master/Welt_Web_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bps20joHXZod",
        "colab_type": "text"
      },
      "source": [
        "# <font color='orange'> Welt Web Scraper </font>\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWXpudN7R3Qc",
        "colab_type": "text"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_F9Q7Td-sRVi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5ce730f1-f44e-47d0-b782-cbdfce8ba013"
      },
      "source": [
        "# Import libraries for processing web text\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "from textblob import TextBlob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from lxml import html\n",
        "\n",
        "# Import these dependencies if using Google Colab \n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLQoyopg1oiY",
        "colab_type": "text"
      },
      "source": [
        "## Define All Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "mh-Z_yZsENF2",
        "colab": {}
      },
      "source": [
        "# Get content of the webpage in an html string format by passing a url \n",
        "def get_html(url):\n",
        "    page = requests.get(url)\n",
        "    html_out = html.fromstring(page.content)\n",
        "    text = page.text\n",
        "    return html_out, text\n",
        "\n",
        "# Convert html into soup to enable soup menthods\n",
        "def get_soup(html_string):\n",
        "    soup = BeautifulSoup(html_string, 'html.parser')\n",
        "    return soup\n",
        "\n",
        "# Extract hyperlinks from soup\n",
        "def get_soup_links(soup):\n",
        "    links = []\n",
        "    for link in soup.find_all('a'):\n",
        "        out_link = link.get('href')\n",
        "        links.append(out_link)\n",
        "    return links\n",
        "\n",
        "# This function is for use with only the Topic pages on reuters.com\n",
        "# Search through ALL links and filter for only those that are for actual articles\n",
        "# links are formatted differently \n",
        "def get_articles_reuters_topics(links, old_url_set):\n",
        "    articles = []\n",
        "    for link in links:\n",
        "        try:\n",
        "            if 'https://www.welt.de' not in link:\n",
        "                if 'article' in link:\n",
        "                  link = 'https://www.welt.de' + link\n",
        "                  if url_check(old_url_set, link) == False:\n",
        "                    articles.append(link)\n",
        "        except:\n",
        "            continue\n",
        "    articles = list(set(articles))\n",
        "    old_url_set = set(articles + list(old_url_set))       \n",
        "    return articles, old_url_set\n",
        "\n",
        "# Check if new urls exists in the old_url_set. if yes, return True; if no, return False\n",
        "# This function is used in the get_articles_reuters_topics function\n",
        "def url_check(old_url_set, url):\n",
        "    url_set = set([url])\n",
        "    test_set = old_url_set & url_set\n",
        "    if len(test_set) == 0:\n",
        "        check = False\n",
        "    else:\n",
        "        check = True\n",
        "    return check\n",
        "\n",
        "# Get html strings from list of article weblinks\n",
        "def get_html_reuters(articles):\n",
        "    soup_list = []\n",
        "    for article in articles:\n",
        "        _, text = get_html(article)\n",
        "        soup = get_soup(text)\n",
        "        soup_list.append(soup)\n",
        "    return soup_list\n",
        "\n",
        "# Break out article_body, article_headline, and article_date from each article in provided hyperlinks and put into a dictionary called: out_list\n",
        "def get_reuters_elements(soup_list, articles):\n",
        "    out_list = []\n",
        "    i = 0\n",
        "    for article in soup_list:\n",
        "        link = articles[i] # I don't think this is used at all here, which means there is no reason to require the second argument: articles\n",
        "        i += 1\n",
        "        try:\n",
        "            article_body = article.find_all(body_class, {'class': body_tag})\n",
        "            article_p = []\n",
        "            for item in article_body:\n",
        "                p_list = item.find_all('p')\n",
        "                for p in p_list:\n",
        "                    article_p.append(p.text)\n",
        "            out_text = ' '.join(article_p)\n",
        "            if out_text == '':\n",
        "              continue\n",
        "            if out_text.startswith('Besondere Reportagen'):\n",
        "              continue\n",
        "            out_dict = dict([('Text',out_text),('url',link)])\n",
        "            out_list.append(out_dict)\n",
        "        except:\n",
        "            print('Unable to decode...skipping article...')\n",
        "            continue\n",
        "\n",
        "    return out_list"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_qCIHy31uSJ",
        "colab_type": "text"
      },
      "source": [
        "## Define URL Variables and Run Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wVxrANXEF-W",
        "colab_type": "text"
      },
      "source": [
        "Tags for different websites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBqKx4fM92CS",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "# Welt classes and tags\n",
        "body_class = 'div'\n",
        "headline_class = 'h2'\n",
        "date_class = 'div'\n",
        "\n",
        "body_tag = 'c-sticky-container'\n",
        "headline_tag = 'c-headline o-dreifaltigkeit__headline rf-o-headline'\n",
        "date_tag = 'c-container c-container--is-stacked'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU0yQpNqLwl4",
        "colab_type": "text"
      },
      "source": [
        "Step 1. Instantiate `old_url_set` to be used in the `get_articles_reuters_topics` function. This is a running log of article links that will be compiled by iterating from steps 2 - 6."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3S4mzVpzp5g1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate empty set to use a running list of hyperlinks while \n",
        "# running the scrape iterations\n",
        "old_url_set = set([])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBkhWZ5iMWq9",
        "colab_type": "text"
      },
      "source": [
        "## Scrape Reuters Topics pages for all the most recent news articles. <font color='orange'>*Run Steps 2 - 3 for each instance of `url` variable, before moving on to the next steps*</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URLqBDPwUbRZ",
        "colab_type": "text"
      },
      "source": [
        "<font color='orange'>Step 2.</font> Define variables for each of Reuters main topics pages. Run this cell for each iteration by uncommenting a different url each time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8a1cAaw3PfL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define url variables\n",
        "# NOTE: You must run these individually through the end of this section\n",
        "# I didn't have time to figure out how to loop through all of them properly\n",
        "# There is a section at the very bottom where you can see that I attempted but ran\n",
        "# into a problem on one of the last functions. \n",
        "\n",
        "# Welt Links\n",
        "#url = r'https://www.welt.de/'\n",
        "url = r'https://www.welt.de/politik/'\n",
        "#url = r'https://www.welt.de/wirtschaft/'\n",
        "#url = r'https://www.welt.de/vermischtes/'\n",
        "#url = r'https://www.welt.de/debatte/'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qGyTkHR3Tos",
        "colab_type": "text"
      },
      "source": [
        "## Scraper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ctx4uUaNM-qy",
        "colab_type": "text"
      },
      "source": [
        "<font color='orange'>Step 3.</font> Get HTML srting from web `url`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJshIC2L4iPA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "660f7713-976b-474e-ddda-9584c0604696"
      },
      "source": [
        "# Pass the each instance of `url` variable to return the web page in HTML format and convert it to a string\n",
        "html_string = str(get_html(url))\n",
        "# Pass the HTML string (of the web page) to get its soup\n",
        "soup = get_soup(html_string)\n",
        "# Find ALL links on within the soup\n",
        "links = get_soup_links(soup)\n",
        "# Use this for Topics Pages only\n",
        "# Filter out only those links that are for actual articles. We only want the \"good\" links\n",
        "# This filters out things like links to images and advertisements or non-news worthy pages\n",
        "articles, old_url_set = get_articles_reuters_topics(links, old_url_set)\n",
        "print(len(articles))\n",
        "# Print out the running list of hyperlinks to see how many you have\n",
        "print(len(old_url_set))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37\n",
            "37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWBBUihX8R0w",
        "colab_type": "text"
      },
      "source": [
        "## <font color='skyblue'>Parse soup from entire list of hyperlinks that you just accumulated</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5M5Po9_OWk2",
        "colab_type": "text"
      },
      "source": [
        "Step 4. Get soup for every link\n",
        "\n",
        "Step 5. Parse the soup for each link into `article_body`, `article_title`, and `article_date`. Create list of dictionaries for each web page\n",
        "\n",
        "Step 6. Run `TextBlob` on list of dictionaries to separate all sentences in a single list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZoenVkMIukU",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2f0712e5-611f-41b4-8b87-99e038d74f8f"
      },
      "source": [
        "# Get soup for each one of the \"good\" links\n",
        "url_links = list(old_url_set) # Convert the running set of links to a list for use in the following functions\n",
        "print(f'Length of url_links: {len(url_links)}')\n",
        "len(url_links)\n",
        "\n",
        "soup_list = get_html_reuters(url_links)\n",
        "print(f'Length of Soup List: {len(soup_list)}')\n",
        "#print(soup_list[0])\n",
        "\n",
        "# Parse the soup for each \"good\" link to get article text, title, and date\n",
        "out_list = get_reuters_elements(soup_list, url_links)\n",
        "print(f'Length of out_list: {len(out_list)}')\n",
        "#out_list[0:2]\n",
        "\n",
        "# Convert text to TextBlob and translate from German to English\n",
        "blob_sentences =[]\n",
        "for i in range(len(out_list)):\n",
        "  try:\n",
        "    blob = out_list[i]['Text']\n",
        "    trans = TextBlob(blob) # Enter string object\n",
        "    trans = trans.translate(to='en')\n",
        "    trans = str(trans) # Change to = 'en' for English\n",
        "    trans = TextBlob(trans)\n",
        "    for item in trans.sentences:\n",
        "      blob_sentences.append(trans)\n",
        "    #print('\\n', i+1, '\\n',trans)\n",
        "  except:\n",
        "    print('got an error ...., skipping article....')\n",
        "print(f'\\nYou have {len(blob_sentences)} total sentences from {i+1} different articles')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of url_links: 37\n",
            "Length of Soup List: 37\n",
            "Length of out_list: 36\n",
            "\n",
            "You have 2011 total sentences from 36 different articles\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XjoXSZDPHLr",
        "colab_type": "text"
      },
      "source": [
        "This is just a troubleshooting section to ensure you're `TextBlob` came out right. You should see a list of stentences, each starting with the word `Sentence`. Check this before moving to the next step."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4fJQzcl5X3h",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Debugging Section\n",
        "# print the first 6 sentences so you see what it looks like\n",
        "blob_sentences[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGJmYoaJYF_n",
        "colab_type": "text"
      },
      "source": [
        "## <font color='skyblue'> Keyword Search </font>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkcNzckEPdOf",
        "colab_type": "text"
      },
      "source": [
        "Step 7. Determine key words used to search for event of interest in all the articles"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xN0ZSBJ510j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ac517a86-f920-435d-8a1c-b99f38c7aa67"
      },
      "source": [
        "# Allow user to type in key words to search the text for\n",
        "# Note this is case sensitive... so you need to make sure you enter your search \n",
        "# Try the entering the following to see some results: corona,COVID,death\n",
        "filter_list = input(\"Enter key words to search for separated by commas. don't use spaces.\\nSearch is case sensitive.\\nExample search: coronavirus,COVID,death\\n\\n\") #.title() # This is still a string... not a list yet"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter key words to search for separated by commas. don't use spaces.\n",
            "Search is case sensitive.\n",
            "Example search: coronavirus,COVID,death\n",
            "\n",
            "America\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8asVgYSPsbu",
        "colab_type": "text"
      },
      "source": [
        "Step 8. Convert keywords into an iterable list for use in the next step\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49R1H35B7aH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e21a946-1608-4e84-8b51-e8c16397f059"
      },
      "source": [
        "# Split filter words and convert into a list for itterating in the next step \n",
        "\n",
        "f = []\n",
        "for word in (filter_list.split(\",\")):  # Split string into separate words, separate by comma\n",
        "  f.append(word)                       # Generate new list containing each key word\n",
        "f # This is now a list of key words that the user typed in"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['America']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTNasDzQLinR",
        "colab_type": "text"
      },
      "source": [
        "Step 9. <font color='skyblue'> Search </font>  All sentences for Key Words and return only those consisting of a key word\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXjYMd1-LUrT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "71d9312d-3c78-434a-eb07-888880a5bf7f"
      },
      "source": [
        "# Instantiate list for holding the sentences\n",
        "sentences = []\n",
        "\n",
        "# Generate empty list of lists to store the sentences with your key words in them\n",
        "for i in range(len(f)):\n",
        "  sentences.append([])\n",
        "#print('Here is what you just made, and empty list of lists: ', sentences, '\\n')\n",
        "\n",
        "# Generate lists of sentences for each key word and plug them into the list of lists from above            \n",
        "for i in range(len(f)):\n",
        "  for sentence in blob_sentences:\n",
        "    if f[i] in sentence:\n",
        "        sentences[i].append(sentence)\n",
        "        \n",
        "# Print number of sentences containing each key word\n",
        "# Print out all sentences containing each key word\n",
        "for i in range(len(f)):\n",
        "  print('='*200)   \n",
        "  print('\\nThere are {} sentences containing the word: {} '.format(len(sentences[i]), f[i])) \n",
        "  print('-'*200)   \n",
        "  #for sentence in sentences[i]:\n",
        "      #print(sentence)\n",
        "\n",
        "# write resulst to text file\n",
        "file_welt = open(\"MyFile_Welt.txt\", \"w\") \n",
        "file_welt.write(str(sentences))\n",
        "file_welt.close()      "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "========================================================================================================================================================================================================\n",
            "\n",
            "There are 124 sentences containing the word: America \n",
            "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcOlndfh9XwA",
        "colab_type": "text"
      },
      "source": [
        "## <font color='black'>Step 10. Store All article data in DataFrame </font>  \n",
        "<font color='grey'>Note: This is not just the filtered data, this contains all information from each web page. While not used in this project, it represents all of the original data used in this run. It can be used for reference.</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjj8Wi-4yOSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c636cc89-6599-4f99-a49b-f29c116d4f11"
      },
      "source": [
        "# Put parsed data into Pandas DataFrame\n",
        "pd.DataFrame(out_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75 Jahre, so alt wird die CDU. Daher hat Part...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Wir freuen uns sehr über Ihr Interesse an WELT...</td>\n",
              "      <td>https://www.welt.de/services/article157550705/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ein russisches Gericht hat den Starregisseur K...</td>\n",
              "      <td>https://www.welt.de/politik/ausland/article210...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ein wichtiger Grundstein des Digitalisierungsp...</td>\n",
              "      <td>https://www.welt.de/Advertorials/deutsche-post...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bei Fragen und Anregungen hilft Ihnen unser Te...</td>\n",
              "      <td>https://www.welt.de/services/article7894222/Ko...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ein weiterer Corona-Ausbruch in einem Fleisch...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Die Stationierung von US-Soldaten in Deutschla...</td>\n",
              "      <td>https://www.welt.de/politik/ausland/article210...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Eigentlich wollte Innenminister Horst Seehofe...</td>\n",
              "      <td>https://www.welt.de/politik/ausland/article210...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>US-Präsident Donald Trump hat den Sturz von St...</td>\n",
              "      <td>https://www.welt.de/politik/ausland/article210...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Lassen Sie sich von einzigartigen Kunstwerken ...</td>\n",
              "      <td>https://www.welt.de/marktplatz/article13286576...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Nach den schweren Ausschreitungen in Stuttgar...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Nun ist sie da: die deutsche Corona-Warn-App....</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Neue Details über die Polizeirazzia bei einem ...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Rauf aufs Rad. In die Pedale treten. Sich den ...</td>\n",
              "      <td>https://www.welt.de/Advertorials/geero/article...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Vom Lockdown in den Kreisen Gütersloh und War...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Klimaaktivisten sind laut französischen Medien...</td>\n",
              "      <td>https://www.welt.de/politik/ausland/article210...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Baden-Württemberg will Schottergärten aus der ...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Die Zahl der Genitalverstümmelungen an Frauen...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Axel Springer SE vertreten durch den Vorstand ...</td>\n",
              "      <td>https://www.welt.de/services/article7893735/Im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Nordrhein-Westfalens Ministerpräsident Armin ...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Das Berliner Landgericht hat den Rauswurf von...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Seit der Flüchtlingskrise im Jahr 2015 sind n...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Nordrhein-Westfalens Ministerpräsident Armin ...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Informativ, hochwertig, traditionell: Die WEL...</td>\n",
              "      <td>https://www.welt.de/apps/article118565353/WELT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>In vielen US-Staaten steigt die Zahl der Infi...</td>\n",
              "      <td>https://www.welt.de/politik/ausland/article210...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Inhaltsverzeichnis 1. Geltungsbereich2. Anbiet...</td>\n",
              "      <td>https://www.welt.de/services/article122129231/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Das US-Repräsentantenhaus hat in einer Abstimm...</td>\n",
              "      <td>https://www.welt.de/politik/ausland/article210...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Jugendschutz ist auch im Internet unverzichtba...</td>\n",
              "      <td>https://www.welt.de/services/article157911156/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Kohlegegner haben in der Nacht Bagger im Brau...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Im Streit über die Autonomie Hongkongs verhäng...</td>\n",
              "      <td>https://www.welt.de/politik/ausland/article210...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Vom Lockdown in den Kreisen Gütersloh und War...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>In der aktuellen Forsa-Umfrage zeigen die Dat...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Sie hat ihren ersten Platz verteidigt. Bundes...</td>\n",
              "      <td>https://www.welt.de/politik/deutschland/articl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>Am besten erkundet man die weite Landschaft im...</td>\n",
              "      <td>https://www.welt.de/Advertorials/ferienregion-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>Die Navigation: Über die Navigationsleiste er...</td>\n",
              "      <td>https://www.welt.de/apps/article174576784/Nutz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>Seit der Flüchtlingskrise im Jahr 2015 sind n...</td>\n",
              "      <td>https://www.welt.de/politik/ausland/article210...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Text                                                url\n",
              "0    75 Jahre, so alt wird die CDU. Daher hat Part...  https://www.welt.de/politik/deutschland/articl...\n",
              "1   Wir freuen uns sehr über Ihr Interesse an WELT...  https://www.welt.de/services/article157550705/...\n",
              "2   Ein russisches Gericht hat den Starregisseur K...  https://www.welt.de/politik/ausland/article210...\n",
              "3   Ein wichtiger Grundstein des Digitalisierungsp...  https://www.welt.de/Advertorials/deutsche-post...\n",
              "4   Bei Fragen und Anregungen hilft Ihnen unser Te...  https://www.welt.de/services/article7894222/Ko...\n",
              "5    Ein weiterer Corona-Ausbruch in einem Fleisch...  https://www.welt.de/politik/deutschland/articl...\n",
              "6   Die Stationierung von US-Soldaten in Deutschla...  https://www.welt.de/politik/ausland/article210...\n",
              "7    Eigentlich wollte Innenminister Horst Seehofe...  https://www.welt.de/politik/ausland/article210...\n",
              "8   US-Präsident Donald Trump hat den Sturz von St...  https://www.welt.de/politik/ausland/article210...\n",
              "9   Lassen Sie sich von einzigartigen Kunstwerken ...  https://www.welt.de/marktplatz/article13286576...\n",
              "10   Nach den schweren Ausschreitungen in Stuttgar...  https://www.welt.de/politik/deutschland/articl...\n",
              "11   Nun ist sie da: die deutsche Corona-Warn-App....  https://www.welt.de/politik/deutschland/articl...\n",
              "12  Neue Details über die Polizeirazzia bei einem ...  https://www.welt.de/politik/deutschland/articl...\n",
              "13  Rauf aufs Rad. In die Pedale treten. Sich den ...  https://www.welt.de/Advertorials/geero/article...\n",
              "14   Vom Lockdown in den Kreisen Gütersloh und War...  https://www.welt.de/politik/deutschland/articl...\n",
              "15  Klimaaktivisten sind laut französischen Medien...  https://www.welt.de/politik/ausland/article210...\n",
              "16  Baden-Württemberg will Schottergärten aus der ...  https://www.welt.de/politik/deutschland/articl...\n",
              "17   Die Zahl der Genitalverstümmelungen an Frauen...  https://www.welt.de/politik/deutschland/articl...\n",
              "18  Axel Springer SE vertreten durch den Vorstand ...  https://www.welt.de/services/article7893735/Im...\n",
              "19   Nordrhein-Westfalens Ministerpräsident Armin ...  https://www.welt.de/politik/deutschland/articl...\n",
              "20   Das Berliner Landgericht hat den Rauswurf von...  https://www.welt.de/politik/deutschland/articl...\n",
              "21   Seit der Flüchtlingskrise im Jahr 2015 sind n...  https://www.welt.de/politik/deutschland/articl...\n",
              "22   Nordrhein-Westfalens Ministerpräsident Armin ...  https://www.welt.de/politik/deutschland/articl...\n",
              "23   Informativ, hochwertig, traditionell: Die WEL...  https://www.welt.de/apps/article118565353/WELT...\n",
              "24   In vielen US-Staaten steigt die Zahl der Infi...  https://www.welt.de/politik/ausland/article210...\n",
              "25  Inhaltsverzeichnis 1. Geltungsbereich2. Anbiet...  https://www.welt.de/services/article122129231/...\n",
              "26  Das US-Repräsentantenhaus hat in einer Abstimm...  https://www.welt.de/politik/ausland/article210...\n",
              "27  Jugendschutz ist auch im Internet unverzichtba...  https://www.welt.de/services/article157911156/...\n",
              "28   Kohlegegner haben in der Nacht Bagger im Brau...  https://www.welt.de/politik/deutschland/articl...\n",
              "29  Im Streit über die Autonomie Hongkongs verhäng...  https://www.welt.de/politik/ausland/article210...\n",
              "30   Vom Lockdown in den Kreisen Gütersloh und War...  https://www.welt.de/politik/deutschland/articl...\n",
              "31   In der aktuellen Forsa-Umfrage zeigen die Dat...  https://www.welt.de/politik/deutschland/articl...\n",
              "32   Sie hat ihren ersten Platz verteidigt. Bundes...  https://www.welt.de/politik/deutschland/articl...\n",
              "33  Am besten erkundet man die weite Landschaft im...  https://www.welt.de/Advertorials/ferienregion-...\n",
              "34   Die Navigation: Über die Navigationsleiste er...  https://www.welt.de/apps/article174576784/Nutz...\n",
              "35   Seit der Flüchtlingskrise im Jahr 2015 sind n...  https://www.welt.de/politik/ausland/article210..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}